<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[谈谈Elasticsearch聚合之如何"group by"与"having"]]></title>
    <url>%2F2018%2F03%2F05%2F%E8%B0%88%E8%B0%88Elasticsearch%E8%81%9A%E5%90%88%E4%B9%8B%E5%A6%82%E4%BD%95%22grouby%22%E4%B8%8E%22having%22%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;最近工作中碰到了一些elasticsearch聚合的问题。明明sql都会写，但是数据导入es里之后，就不知道怎么写Query DSL取出来TmT,有木有。在这里记录一下,并整理出一个例子，供大家直接上手尝试。 开始扯淡0v0我们就从问题出发。首先起个elasticsearch 5.x(macOS推荐brew 或者 docker),保证localhost:9200能访问通。然后建立一个type，cURL：12345678910111213141516$ curl -X PUT \ http://localhost:9200/shirts \ -H 'Cache-Control: no-cache' \ -H 'Content-Type: application/json' \ -H 'Postman-Token: 360fcbcc-75ef-6dac-baec-3e5f02b9f3b8' \ -d '&#123; "mappings": &#123; "item": &#123; "properties": &#123; "brand": &#123; "type": "keyword"&#125;, "color": &#123; "type": "keyword"&#125;, "model": &#123; "type": "keyword"&#125; &#125; &#125; &#125; &#125;' 然后mock一些数据，cURL:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950$ curl -X PUT \ http://localhost:9200/shirts/item/1 \ -H 'Cache-Control: no-cache' \ -H 'Content-Type: application/json' \ -H 'Postman-Token: f767d0ad-a6cc-681c-36a1-90843594629e' \ -d '&#123; "brand": "gucci", "color": "red", "model": "big" &#125;'$ curl -X PUT \ http://localhost:9200/shirts/item/2 \ -H 'Cache-Control: no-cache' \ -H 'Content-Type: application/json' \ -H 'Postman-Token: f767d0ad-a6cc-681c-36a1-90843594629e' \ -d '&#123; "brand": "gucci", "color": "red", "model": "small" &#125;'$ curl -X PUT \ http://localhost:9200/shirts/item/3 \ -H 'Cache-Control: no-cache' \ -H 'Content-Type: application/json' \ -H 'Postman-Token: f767d0ad-a6cc-681c-36a1-90843594629e' \ -d '&#123; "brand": "nike", "color": "white", "model": "ugly" &#125;'$ curl -X PUT \ http://localhost:9200/shirts/item/4 \ -H 'Cache-Control: no-cache' \ -H 'Content-Type: application/json' \ -H 'Postman-Token: f767d0ad-a6cc-681c-36a1-90843594629e' \ -d '&#123; "brand": "nike", "color": "red", "model": "nice" &#125;'$ curl -X PUT \ http://localhost:9200/shirts/item/5 \ -H 'Cache-Control: no-cache' \ -H 'Content-Type: application/json' \ -H 'Postman-Token: f767d0ad-a6cc-681c-36a1-90843594629e' \ -d '&#123; "brand": "puma", "color": "yellow", "model": "honor" &#125;' brand是品牌，color是颜色,model是款式。然后brand,color,model三者确定数据唯一性，其他没任何限制，那么问题来了，只有一种颜色的品牌 总共有几个?下面是对应的sql:1234567891011121314151617CREATE TABLE `item` ( `id` int(11) NOT NULL AUTO_INCREMENT, `brand` varchar(20) DEFAULT NULL, `color` varchar(20) DEFAULT NULL, `model` varchar(20) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;INSERT INTO item (id, brand, color, model) VALUES (1, 'gucci', 'red', 'big');INSERT INTO item (id, brand, color, model) VALUES (2, 'gucci', 'red', 'small');INSERT INTO item (id, brand, color, model) VALUES (3, 'nike', 'white', 'ugly');INSERT INTO item (id, brand, color, model) VALUES (4, 'nike', 'red', 'nice');INSERT INTO item (id, brand, color, model) VALUES (5, 'puma', 'yellow', 'honor');#1 返回只拥有一种颜色的品牌select cc.brand from (select brand,color from item GROUP BY brand, color)cc GROUP BY cc.brand HAVING count(cc.brand)=1#2 返回只拥有一种颜色的品牌 总共个数select count(1) FROM (select cc.brand from (select brand,color from item GROUP BY brand, color)cc GROUP BY cc.brand HAVING count(cc.brand)=1)dd; 上述结果分别为 gucci,puma; 2;那么es的 Query DSL如何写呢？直接上答案：123456789101112131415161718192021222324252627282930$ curl -X POST \ http://localhost:9200/shirts/_search \ -H 'Cache-Control: no-cache' \ -H 'Content-Type: application/json' \ -H 'Postman-Token: a95749ae-f92a-4f3d-0b7d-c0fec107cf5d' \ -d '&#123; "aggs": &#123; "groupby1": &#123; "terms": &#123; "field": "brand" &#125;, "aggs": &#123; "groupby2": &#123; "cardinality": &#123; "field": "color" &#125; &#125;, "sales_bucket_filter": &#123; "bucket_selector": &#123; "buckets_path": &#123; "groupby2": "groupby2" &#125;, "script": "params.groupby2 == 1" &#125; &#125; &#125; &#125; &#125; ,"size": 0&#125;' 返回的response为：123456789101112131415161718192021222324252627282930313233343536&#123; "took": 1, "timed_out": false, "_shards": &#123; "total": 5, "successful": 5, "failed": 0 &#125;, "hits": &#123; "total": 5, "max_score": 0, "hits": [] &#125;, "aggregations": &#123; "groupby1": &#123; "doc_count_error_upper_bound": 0, "sum_other_doc_count": 0, "buckets": [ &#123; "key": "gucci", "doc_count": 2, "groupby2": &#123; "value": 1 &#125; &#125;, &#123; "key": "puma", "doc_count": 1, "groupby2": &#123; "value": 1 &#125; &#125; ] &#125; &#125;&#125; &emsp;&emsp;最后只要取buckets.size就好了（有点间接0 0，网上实在是搜不到如何直接取count的那种了，有好方法，欢迎留言），大功告成。至于如何理解这个Query DSL，其实和sql很像，你可以对比我写的sql来理解。如果你是想搞清楚到底是咋回事的话，还是直接看官方文档吧，es文档写的比较清楚且好理解,下面是中英文文档的地址，哪里不懂看哪里即可： es的aggregations(聚合) 官方文档 中文文档 es的cardinality字段啥意思(即Cardinality Aggregation) 官方文档 中文文档 es的如何group by field1,field2(即Children Aggregation) 官方文档 中文文档 我上面使用的 sales_bucket_filter是什么意思(即Bucket Script Aggregation) 官方文档 中文文档 题外话在es5.x开始 string字段就被当作废弃字段，而取而代之的是text,keyword。text你可以近似的理解成2.x里的：123456789&#123;"mappings": &#123; "item": &#123; "properties": &#123; "test_word": &#123; "type": "string","index": "analyzed"&#125; &#125; &#125; &#125;&#125; 而keyword则理解成：123456789&#123;"mappings": &#123; "item": &#123; "properties": &#123; "test_word": &#123; "type": "string","index": "not_analyzed"&#125; &#125; &#125; &#125;&#125;]]></content>
      <categories>
        <category>elasticsearch</category>
      </categories>
      <tags>
        <tag>elasticsearch Aggregations</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[奇葩问题与神奇想法]]></title>
    <url>%2F2018%2F03%2F01%2F%E7%96%91%E9%97%AE%2F</url>
    <content type="text"><![CDATA[平时工作或者学习时，碰到的奇葩问题以及有时候自己坑自己的神奇想法 T-T，如果有人对某些东西有见解，可以在下面留言(梯子自备) 奇葩问题神奇想法 在mysql中，select id from tableA where id in (select id from tableB where 1=0)的结果并没有报错，并返回预期的结果，即什么都找不到。用过mybatis的人都知道，我们用foreach标签配in后面的参数的时候，都要特别注意list为空的情况，因为 where xxx in ()这样是会报错。那mysql内部是如何避免这种错误的呢0 0？]]></content>
  </entry>
  <entry>
    <title><![CDATA[JAVA知识点整理]]></title>
    <url>%2F2018%2F02%2F28%2F%E9%9B%86%E5%90%88%2F</url>
    <content type="text"><![CDATA[这里是阅读java8源码以及一些java知识的随笔，没头没尾，不严谨，仅自己看看 集合 List ArrayList 有3种构造函数。无参则elementData = {};有int参则负数报错，非负数初始化相应大小数组;Collection&lt;? extends E&gt; c入参的，直接elementData = c.toArray(); Integer.MAX_VALUE+1 返回的是最大的负数而不是最小的负数。所以c= Integer.MAX_VALUE+1 ,c= c-2,最终c为正数 负数向右移,不管移多少位始终都是负数 add和addAll方法会判断elementData这个数组容器是否为空，为空则初始化，如果是add则值为默认的10，如果是addAll方法，则选入参 size和10较大的一个值 add(E e)方法 如果未初始化，则初始化数组，默认长度为10 如果初始化过后，则每次扩容，扩容为 newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1),即原来的1.5倍,如果为原来的1.5倍容量溢出了，则 如果上面一步扩容为原来的1.5倍超过Integer.MAX_VALUE-8了但又没溢出，则令容量等于Integer.MAX_VALUE，否则报错 Arrays.copyOf 是浅拷贝，浅拷贝是按位拷贝对象，它会创建一个新对象，这个对象有着原始对象属性值的一份精确拷贝。如果属性是基本类型，拷贝的就是基本类型的值，如果属性是内存地址（引用类型），拷贝的就是内存地址 add(int index, E element) 检查index是否比 size大，比0小 之后就是容量检测，扩容,溢出检测等，和上同 之后调用System.arraycopy(elementData, index, elementData, index + 1,size - index)。 最后elementData[index] = element; size++; get(int index) 判断范围，越界报错 return elementData[index] set(int index, E element) 在 index位置上放入新值，返回旧值 remove(int index) 删除index上的值，调用System.arraycopy，return 删掉的值 返回的是删掉的值 remove(Object o) 循环，遍历，找到一个，就删掉，并调用System.arraycopy 返回的是bool removeAll(Collection&lt;?&gt; c) for循环 判断 c里面是否有list里的元素c.contains(elementData[r])==false,如果没有，则 elementData[w++] = elementData[r]。 如果抛异常了，则将后面还没遍历到的数据放到从索引w处开始的地方 subList(int fromIndex, int toIndex) return new SubList(this, 0, fromIndex, toIndex) 从 this，可以看出生成的只是当前list的截取视图 trimToSize 去掉扩容多于的部分，使数组长度好等于size contains(Object o ) 循环遍历数组 找到equals的返回true LinkedList add(int index, E element) 校验 index不能想超过size 如果list里已经又一个元素2，如果 add(0,1),则元素list数据为[1,2],如果add(1,2),则结果为[2,1],即可决定加在链表头还是尾，或者是链表任意一个位置 add(E e)方法 校验 在链表尾加一个node addAll(int index, Collection&lt;? extends E&gt; c) 会将 collection类型的数据先变成一个链表，再插入原先链表的任意位置，位置随index而定，与add方法类似 node(int index) 首先会判断 index &lt; (size &gt;&gt; 1) 是否成立，来判断从头开始找还是从尾巴开始找，所以随机读取效率低 get(int index) 检验 调用node(int index) remove() 删除第一个 set(int index, E element) 直接通过node(i)方法找到该node,然后直接替换该node.item 2种构造函数。无参构造函数，就是个空方法0 0，有参构造函数调用addAll方法， 疑问 System.arraycopy(elementData, index, elementData, index + 1,size - index)，数组自己拷贝到自己时，明明有重叠部分，却并不会覆盖？由于是native方法，猜测有可能是从数组尾部开始复制的！ list 里有个 modcount有啥用？ 后来发现有些方法里有判断 modCount == expectedModCount，所以modCount是用来保证，多线程操作时，抛出错误，阻止方法执行]]></content>
      <categories>
        <category>JAVA知识点</category>
      </categories>
      <tags>
        <tag>JAVA知识点</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NIFI-安装]]></title>
    <url>%2F2018%2F02%2F27%2Fnifi-1%2F</url>
    <content type="text"><![CDATA[NIFI网上的中文资料是真的少。特别是用docker启动NIFI。记录下来，当传家宝=v = 安装NIFImacOS没有 brew 的先安装brew1$ brew install nifi 通过brew安装完之后12$ cd /usr/local/Cellar/nifi/1.5.0/bin$ sudo nifi start 注意，上述路径有可能和作者不一样。因为对应的nifi版本不一样！！！ Linux官网下载,下完之后找到工程目录 bin 然后 1$ sudo nifi start 附加牢骚(我懒得试0v0,就试了用docker启动ubuntu16.04,然后不行)： Ubuntu / Debian 系的可以试试看： 1$ sudo apt-get install nifi Centos / Redhat 可以试试: 1$ sudo yum install nifi 以上安装方法默认 java环境已经安装好 并且是jdk1.8或以上。 docker容器大爱，只需要有docker环境就好了,非常方便，推荐使用docker安装12$ docker pull apache/nifi:1.5.0$ docker run --name nifi -p 8080:8080 -d apache/nifi:1.5.0 启动成功会显示该新建容器的id(这个id每个人都是不一样的):1$ c78fabb5d1eb99be5de736499f3c833e6e7a6d0608ef4457ee348887e22a35ce 关闭容器后，想第二次启动该容器,不应该重复上述的docker run命令，否则会报如下错误:123$ docker run --name nifi -p 8080:8080 -d apache/nifi:1.5.0$ docker: Error response from daemon: Conflict. The container name "/nifi" is already in use by container "c78fabb5d1eb99be5de736499f3c833e6e7a6d0608ef4457ee348887e22a35ce". You have to remove (or rename) that container to be able to reuse that name. See 'docker run --help'. 应根据名字或者id来启动，名称即 –name 后面的参数，这里是nifi，所以命令如下:1$ docker start nifi 启动 docker 容器命令后面也可以加个 –rm,即1$ docker run --rm --name nifi -p 8080:8080 -d apache/nifi:1.5.0 这个参数是说容器退出后随之将其删除。这样你每次起的都是一个全新的镜像。 搞定收工]]></content>
      <categories>
        <category>NIFI</category>
      </categories>
      <tags>
        <tag>NIFI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo Next折腾记录]]></title>
    <url>%2F2018%2F02%2F26%2Fhexo-next-1%2F</url>
    <content type="text"><![CDATA[本文是我折腾Hexo Next主题的一些心得，有些坑，真的是不踩不知道，一踩要踩一天TmT。这里我总结一下，让后来人站在我这个巨人的肩膀上 =v =嘎嘎。 &emsp;&emsp;首先，如果对Hexo一无所知，不知道是个什么东西的，出门左转 -&gt; Hexo 官方文档。我稍微解释一下Hexo到底是什么吧，因为我刚开始接触到，好多文档都没说它到底有个卵用，就开始长篇大论了，这让我搞了好久才知道Hexo到底有啥用，我为啥要用。Hexo其实可以理解为一个Html生成器，给不会前端(html)或者想快速搭建自己博客的人提供。你只需在Hexo提供的工程目录下的配置文件里配置一些参数，以及通过markdown语法写下自己的博文，Hexo就帮你负责生成相应的Html和js，这样你就可以只关心自己博客该如何写，而用考虑其他琐事(如何 html怎么写，css怎么写之类的)。&emsp;&emsp;那你可能又问为啥不用csdn 或者掘金之类的网站提供的博客功能。我的回答就是因为这样显得很装B，哈哈，说好听点，就是感觉比较 geek！额，扯远了，当你看完Hexo的官方文档，你对Hexo有个大概了解，以及如何基本操作后，你可以看看Next主题，出门右转 -&gt; Next 官方文档。&emsp;&emsp;废话讲完，进入踩坑细节。接下来的内容是建立在Hexo文档以及Next文档都已经了解的情况下写的。 那些天坑 Hexo 的 _config.xml里的 url:配置你的域名时，一定要加上http://或者https://,比如url: http://yewennuan.com。不加的话，如果你添加了生成站点地图sitemap.xml的功能，你会发现Google的Search Console收录你的站点地图也就是sitemap时，会报错，说sitemap地址格式错误T T。 如果你用 github pages托管Hexo生成的静态站点，那么baidu的爬虫是爬不到内容的，因为github 不让百度的爬虫爬取0-0(这不是坑爹吗，我去)，解决办法就是买个域名，如yewennuan.com，百度爬虫访问该域名解析到国内的静态资源托管网站 如Coding.net,你可以理解为中国的github，然后他也有pages服务，这个coding的pages服务如何搞可以参考Google搜索。具体DNS解析如何操作，请看下面图片:这是阿里云的云解析 DNS控制台,进行如下设置。(由于百度爬虫存在DNS缓存，所以这个方案还没得到验证，等验证完，我在过来更新！) 如果你的Next主题集成 disqus评论插件，发现怎么搞也出现不了。然后，你再看看这片文章结尾有没有评论栏，如果没有，额，兄弟，不用找了，墙里面是看不见的。你需要一个梯子╮(╯▽╰)╭ 如果你在万网购买了一个域名，然后你想解析到你的xxx.github.io。你只需在万网控制台(被阿里云收购了，也就是阿里云的云解析DNS控制台)进行如下操作：你可能又会问A记录为啥为啥指向这两个ip啊,可以见下图:,人家github pages的帮助文档就叫你指向这两个ip。然后你又会问CNAME记录为啥还要在解析一遍到xxx.github.io上啊，没有这个CNAME记录的配置，你会发现在chrome输入xxx.com如yewennuan.com也能访问到自己的博客了。其实增加CNAME记录是为了解析www域名前缀，你会发现没有配置CNAME,www.xxx.com如www.yewennuan.com是访问不通的，配置了就ok了！(这边只是讲了解析的一部分，还要在自己工程里配置CNAME文件以及github上配置域名等等就没赘述，自己Google或者官方文档看看)&emsp;&emsp;额，当时网上找了好久，我就是不知道为啥域名要解析到这两个ip，，网上一些教学文档也不说一下出处，还有些说ping一下 xxx.github.io，得到ip，然后将域名解析上去，尼玛。 暂时没了，以后被坑了继续补充]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
</search>
